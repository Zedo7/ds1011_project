{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# src/pe ? Absolute\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Absolute positional encoding (sinusoidal or learned).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\nimport torch, math\ndef sinusoidal_positions(L, d_model):\n    pe = torch.zeros(L, d_model)\n    position = torch.arange(0, L, dtype=torch.float32).unsqueeze(1)\n    div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n    pe[:,0::2] = torch.sin(position*div); pe[:,1::2] = torch.cos(position*div)\n    return pe\nclass AbsolutePE:\n    def __init__(self, d_model, max_len=16384, learned=False):\n        self.d_model=d_model; self.max_len=max_len; self.learned=learned\n        self.table = torch.nn.Embedding(max_len, d_model) if learned else sinusoidal_positions(max_len, d_model)\n    def add(self, x, start=0):\n        if isinstance(self.table, torch.nn.Embedding):\n            idx = torch.arange(start, start+x.size(1), device=x.device)\n            return x + self.table(idx)\n        return x + self.table[start:start+x.size(1)].to(x.device)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}